{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import vgg_model\n",
    "import torch as ch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm as pbar\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_folder(path):\n",
    "    filepaths = os.listdir(path)\n",
    "    do_not_work = []\n",
    "    for file in filepaths:\n",
    "        try:\n",
    "            im = Image.open(os.path.join(path, file))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            do_not_work.append(os.path.join(path, file))\n",
    "    for path in do_not_work:\n",
    "        os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = \"./car_vs_bird/car/\"\n",
    "for path in os.listdir(basepath):\n",
    "    clean_folder(os.path.join(basepath, path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basepath = \"./car_vs_bird/bird/\"\n",
    "# for path in os.listdir(basepath):\n",
    "#     clean_folder(os.path.join(basepath, path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before: 5177 car, 3400 bird\n",
    "# After:  2123 car, 1351 bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next up: use pretrained CIFAR-10 classifiers and finetune for 1-vs-rest concept classification (last 2 layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ch.device('cuda:0' if ch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloaders(params):\n",
    "    transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.ColorJitter(.25,.25,.25),\n",
    "                                          transforms.RandomRotation(2),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "    \n",
    "    transform_validation = transforms.Compose([transforms.ToTensor(),\n",
    "                                               transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "    \n",
    "    trainset = torchvision.datasets.CIFAR10(root=params['path'], train=True, transform=transform_train)\n",
    "    testset  = torchvision.datasets.CIFAR10(root=params['path'], train=False, transform=transform_validation)\n",
    "    \n",
    "    trainloader = ch.utils.data.DataLoader(trainset, batch_size=params['batch_size'], shuffle=True, num_workers=4)\n",
    "    testloader  = ch.utils.data.DataLoader(testset, batch_size=params['batch_size'], shuffle=False, num_workers=4)\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, params, mapping, threshold=0.5):\n",
    "    \n",
    "    model = model.to(params['device']).eval()     \n",
    "    phase = 'validation'\n",
    "    logs = {'Accuracy': 0.0, 'F1-Score': 0.0}\n",
    "            \n",
    "    preds, gt = [], []\n",
    "    # Iterate over data\n",
    "    for image, label in params[phase+'_loader']:\n",
    "        image = image.to(params['device'])\n",
    "        # Convert labels using the given mapping\n",
    "        for i, l in enumerate(label):\n",
    "            gt.append(mapping[l.item()])\n",
    "\n",
    "        with ch.no_grad():\n",
    "            prediction = ch.sigmoid(model(image)).cpu()\n",
    "            for pred in prediction:\n",
    "                preds.append(pred >= threshold)\n",
    "\n",
    "    logs['Accuracy'] = accuracy_score(gt, preds)\n",
    "    logs['F1-Score'] = f1_score(gt, preds)\n",
    "    \n",
    "    return logs['Accuracy'], logs['F1-Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_model(model, params, mapping, threshold=0.3):\n",
    "    \n",
    "    writer = SummaryWriter('runs/' + params['description'])\n",
    "    model = model.to(params['device'])\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "    total_updates = params['num_epochs'] * len(params['train_loader'])\n",
    "    \n",
    "    criterion = ch.nn.BCEWithLogitsLoss()\n",
    "    best_f1 = test_model(model, params, mapping)[1]\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "    for epoch in range(params['num_epochs']):\n",
    "        # Each epoch has a training and validation phase\n",
    "        print(\"Epoch : %d\" % (epoch + 1))\n",
    "        for phase in ['train', 'validation']:\n",
    "            \n",
    "            # Loss accumulator for each epoch\n",
    "            logs = {'Loss': 0.0,\n",
    "                    'Accuracy': 0.0,\n",
    "                    'Precision': 0.0,\n",
    "                    'Recall': 0.0}\n",
    "            \n",
    "            # Set the model to the correct phase\n",
    "            model.train() if phase == 'train' else model.eval()\n",
    "            \n",
    "            # Iterate over data\n",
    "            for image, label in params[phase+'_loader']:\n",
    "                # Convert labels using the given mapping\n",
    "                for i, l in enumerate(label):\n",
    "                    label[i] = mapping[l.item()]\n",
    "                \n",
    "                image = image.to(params['device'])\n",
    "                label = label.to(params['device'])\n",
    "\n",
    "                # Zero gradient\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with ch.set_grad_enabled(phase == 'train'):\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    prediction = model(image)\n",
    "                    loss = criterion(prediction, label.unsqueeze(1).float())\n",
    "                    accuracy = ch.sum((ch.sigmoid(prediction) >= threshold) == label.data).item()\n",
    "                    \n",
    "                    with ch.no_grad():\n",
    "                        y_ = ((ch.sigmoid(prediction)).flatten().cpu().numpy() >= threshold) * 1\n",
    "\n",
    "                    # Update log\n",
    "                    logs['Loss'] += image.shape[0]*loss.detach().item()\n",
    "                    logs['Accuracy'] += accuracy\n",
    "                    logs['Precision'] += image.shape[0]*precision_score(label.data.cpu(), y_)\n",
    "                    logs['Recall'] += image.shape[0]*recall_score(label.data.cpu(), y_)\n",
    "\n",
    "                    # Backward pass\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "            \n",
    "            # Normalize and write the data to TensorBoard\n",
    "            logs['Loss'] /= len(params[phase+'_loader'].dataset)\n",
    "            logs['Accuracy'] /= len(params[phase+'_loader'].dataset)\n",
    "            logs['Precision'] /= len(params[phase+'_loader'].dataset)\n",
    "            logs['Recall'] /= len(params[phase+'_loader'].dataset)\n",
    "            \n",
    "            f1_score = (2 * logs['Precision'] * logs['Recall']) / (logs['Precision'] + logs['Recall'])\n",
    "            writer.add_scalars('Loss', {phase: logs['Loss']}, epoch)\n",
    "            writer.add_scalars('Accuracy', {phase: logs['Accuracy']}, epoch)\n",
    "            writer.add_scalars('F-1', {phase: f1_score}, epoch)\n",
    "            \n",
    "            print(\"%s loss: %.3f , accuracy: %.3f, F-1: %.3f\" % (phase, logs['Loss'], logs['Accuracy'], f1_score))\n",
    "\n",
    "            # Save the best weights\n",
    "            if phase == 'validation' and f1_score > best_f1:\n",
    "                best_f1 = f1_score\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "                 \n",
    "        # Write best weights to disk\n",
    "        if epoch % params['check_point'] == 0 or epoch == params['num_epochs']-1:\n",
    "            ch.save(best_model, params['description'] + '.pt')\n",
    "    \n",
    "    final_accuracy = test_model(model, params, mapping)[0]\n",
    "    writer.add_text('Final_Accuracy', str(final_accuracy), 0)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder_loaders(params):\n",
    "    transform_train = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.ColorJitter(.25,.25,.25),\n",
    "                                          transforms.RandomRotation(2),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "    \n",
    "    transform_validation = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                               transforms.ToTensor(),\n",
    "                                               transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "    \n",
    "    trainset = torchvision.datasets.ImageFolder(root=os.path.join(params['path'], \"train\"), transform=transform_train)\n",
    "    testset  = torchvision.datasets.ImageFolder(root=os.path.join(params['path'], \"val\"),   transform=transform_validation)\n",
    "    \n",
    "    trainloader = ch.utils.data.DataLoader(trainset, batch_size=params['batch_size'], shuffle=True, num_workers=4)\n",
    "    testloader  = ch.utils.data.DataLoader(testset, batch_size=params['batch_size'], shuffle=False, num_workers=4)\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_into_binary(m):\n",
    "    # Freeze feature extraction layers\n",
    "    for n, l in m.named_parameters():\n",
    "        if \"features.\" in n:\n",
    "            l.requires_grad  = False\n",
    "    # Swap out final classification layer\n",
    "    m.classifier[6] = ch.nn.Linear(m.classifier[6].weight.shape[1], 1)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bird Concept Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feather': None, 'feet': None, 'beak': None, 'eyes': None, 'wings': None}\n"
     ]
    }
   ],
   "source": [
    "basepath = \"./car_vs_bird/bird/train\"\n",
    "bird_classifiers = {x:None for x in os.listdir(basepath)}\n",
    "print(bird_classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = {'path': '/p/adversarialml/as9rw/dlvr_project/car_vs_bird/bird/', 'batch_size': 128}\n",
    "train_loader, validation_loader = make_folder_loaders(data_params)\n",
    "train_params = {'description': 'Bird-Concepts',\n",
    "                'num_epochs': 10,\n",
    "                'check_point': 5, 'device': device,\n",
    "                'train_loader': train_loader, 'validation_loader': validation_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beak', 'eyes', 'feather', 'feet', 'wings']\n",
      "{'beak': 0, 'eyes': 1, 'feather': 2, 'feet': 3, 'wings': 4}\n",
      "['beak', 'eyes', 'feather', 'feet', 'wings']\n",
      "{'beak': 0, 'eyes': 1, 'feather': 2, 'feet': 3, 'wings': 4}\n"
     ]
    }
   ],
   "source": [
    "print(train_loader.dataset.classes)\n",
    "print(train_loader.dataset.class_to_idx)\n",
    "print(validation_loader.dataset.classes)\n",
    "print(validation_loader.dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_classifiers['beak'] = finetune_into_binary(vgg_model.vgg19_bn(pretrained=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "train loss: 0.662 , accuracy: 36.755, F-1: 0.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.620 , accuracy: 32.737, F-1: 0.274\n",
      "Epoch : 2\n",
      "train loss: 0.623 , accuracy: 40.076, F-1: 0.447\n",
      "validation loss: 0.595 , accuracy: 36.290, F-1: 0.273\n",
      "Epoch : 3\n",
      "train loss: 0.602 , accuracy: 44.632, F-1: 0.446\n",
      "validation loss: 0.572 , accuracy: 45.668, F-1: 0.262\n",
      "Epoch : 4\n",
      "train loss: 0.596 , accuracy: 49.156, F-1: 0.444\n",
      "validation loss: 0.561 , accuracy: 54.912, F-1: 0.257\n",
      "Epoch : 5\n",
      "train loss: 0.589 , accuracy: 57.083, F-1: 0.444\n",
      "validation loss: 0.551 , accuracy: 65.484, F-1: 0.252\n",
      "Epoch : 6\n",
      "train loss: 0.587 , accuracy: 61.983, F-1: 0.427\n",
      "validation loss: 0.548 , accuracy: 70.235, F-1: 0.238\n",
      "Epoch : 7\n",
      "train loss: 0.584 , accuracy: 64.463, F-1: 0.439\n",
      "validation loss: 0.548 , accuracy: 71.350, F-1: 0.238\n",
      "Epoch : 8\n",
      "train loss: 0.581 , accuracy: 64.947, F-1: 0.456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.544 , accuracy: 70.977, F-1: 0.240\n",
      "Epoch : 9\n",
      "train loss: 0.583 , accuracy: 64.844, F-1: 0.452\n",
      "validation loss: 0.545 , accuracy: 67.765, F-1: 0.245\n",
      "Epoch : 10\n",
      "train loss: 0.578 , accuracy: 61.785, F-1: 0.476\n",
      "validation loss: 0.542 , accuracy: 70.092, F-1: 0.237\n"
     ]
    }
   ],
   "source": [
    "beak_mapping = {0:1, 1:0, 2:0, 3:0, 4:0}\n",
    "finetune_model(bird_classifiers['beak'], train_params, beak_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.00 : Acc 0.256, F-1 0.407\n",
      "Threshold 0.10 : Acc 0.256, F-1 0.407\n",
      "Threshold 0.20 : Acc 0.300, F-1 0.420\n",
      "Threshold 0.30 : Acc 0.613, F-1 0.485\n",
      "Threshold 0.40 : Acc 0.744, F-1 0.000\n",
      "Threshold 0.50 : Acc 0.744, F-1 0.000\n",
      "Threshold 0.60 : Acc 0.744, F-1 0.000\n",
      "Threshold 0.70 : Acc 0.744, F-1 0.000\n",
      "Threshold 0.80 : Acc 0.744, F-1 0.000\n",
      "Threshold 0.90 : Acc 0.744, F-1 0.000\n",
      "Threshold 1.00 : Acc 0.744, F-1 0.000\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    acc = test_model(bird_classifiers['beak'], train_params, beak_mapping, i / 10)\n",
    "    print(\"Threshold %.2f : Acc %.3f, F-1 %.3f\" % (i/10, acc[0], acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "train loss: 0.624 , accuracy: 19.035, F-1: 0.220\n",
      "validation loss: 0.514 , accuracy: 19.788, F-1: 0.171\n",
      "Epoch : 2\n",
      "train loss: 0.487 , accuracy: 52.699, F-1: 0.192\n",
      "validation loss: 0.451 , accuracy: 68.244, F-1: 0.159\n",
      "Epoch : 3\n",
      "train loss: 0.440 , accuracy: 85.583, F-1: 0.210\n",
      "validation loss: 0.411 , accuracy: 103.088, F-1: 0.017\n",
      "Epoch : 4\n",
      "train loss: 0.413 , accuracy: 107.144, F-1: 0.068\n",
      "validation loss: 0.400 , accuracy: 104.051, F-1: nan\n",
      "Epoch : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.405 , accuracy: 108.925, F-1: 0.021\n",
      "validation loss: 0.387 , accuracy: 104.267, F-1: nan\n",
      "Epoch : 6\n",
      "train loss: 0.398 , accuracy: 110.535, F-1: 0.013\n",
      "validation loss: 0.384 , accuracy: 104.267, F-1: nan\n",
      "Epoch : 7\n",
      "train loss: 0.392 , accuracy: 110.194, F-1: 0.016\n",
      "validation loss: 0.379 , accuracy: 104.267, F-1: nan\n",
      "Epoch : 8\n",
      "train loss: 0.394 , accuracy: 110.258, F-1: nan\n",
      "validation loss: 0.375 , accuracy: 104.267, F-1: nan\n",
      "Epoch : 9\n",
      "train loss: 0.396 , accuracy: 110.503, F-1: 0.018\n",
      "validation loss: 0.373 , accuracy: 104.267, F-1: nan\n",
      "Epoch : 10\n",
      "train loss: 0.384 , accuracy: 110.265, F-1: 0.016\n",
      "validation loss: 0.369 , accuracy: 104.267, F-1: nan\n"
     ]
    }
   ],
   "source": [
    "bird_classifiers['eyes'] = finetune_into_binary(vgg_model.vgg19_bn(pretrained=True))\n",
    "eyes_mapping = {0:0, 1:1, 2:0, 3:0, 4:0}\n",
    "finetune_model(bird_classifiers['eyes'], train_params, eyes_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.00 : Acc 0.115, F-1 0.207\n",
      "Threshold 0.10 : Acc 0.233, F-1 0.190\n",
      "Threshold 0.20 : Acc 0.841, F-1 0.127\n",
      "Threshold 0.30 : Acc 0.885, F-1 0.000\n",
      "Threshold 0.40 : Acc 0.885, F-1 0.000\n",
      "Threshold 0.50 : Acc 0.885, F-1 0.000\n",
      "Threshold 0.60 : Acc 0.885, F-1 0.000\n",
      "Threshold 0.70 : Acc 0.885, F-1 0.000\n",
      "Threshold 0.80 : Acc 0.885, F-1 0.000\n",
      "Threshold 0.90 : Acc 0.885, F-1 0.000\n",
      "Threshold 1.00 : Acc 0.885, F-1 0.000\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    acc = test_model(bird_classifiers['eyes'], train_params, eyes_mapping, i / 10)\n",
    "    print(\"Threshold %.2f : Acc %.3f, F-1 %.3f\" % (i/10, acc[0], acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "train loss: 0.594 , accuracy: 21.633, F-1: 0.243\n",
      "validation loss: 0.502 , accuracy: 20.995, F-1: 0.181\n",
      "Epoch : 2\n",
      "train loss: 0.485 , accuracy: 55.654, F-1: 0.248\n",
      "validation loss: 0.438 , accuracy: 92.677, F-1: 0.027\n",
      "Epoch : 3\n",
      "train loss: 0.447 , accuracy: 97.543, F-1: 0.087\n",
      "validation loss: 0.411 , accuracy: 102.498, F-1: nan\n",
      "Epoch : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.429 , accuracy: 107.683, F-1: nan\n",
      "validation loss: 0.400 , accuracy: 102.498, F-1: nan\n",
      "Epoch : 5\n",
      "train loss: 0.419 , accuracy: 108.590, F-1: nan\n",
      "validation loss: 0.397 , accuracy: 102.498, F-1: nan\n",
      "Epoch : 6\n",
      "train loss: 0.419 , accuracy: 109.336, F-1: nan\n",
      "validation loss: 0.396 , accuracy: 102.498, F-1: nan\n",
      "Epoch : 7\n",
      "train loss: 0.425 , accuracy: 109.231, F-1: nan\n",
      "validation loss: 0.394 , accuracy: 102.498, F-1: nan\n",
      "Epoch : 8\n",
      "train loss: 0.415 , accuracy: 109.504, F-1: nan\n",
      "validation loss: 0.392 , accuracy: 102.498, F-1: nan\n",
      "Epoch : 9\n",
      "train loss: 0.415 , accuracy: 109.604, F-1: nan\n",
      "validation loss: 0.391 , accuracy: 102.498, F-1: nan\n",
      "Epoch : 10\n",
      "train loss: 0.416 , accuracy: 109.336, F-1: nan\n",
      "validation loss: 0.391 , accuracy: 102.498, F-1: nan\n"
     ]
    }
   ],
   "source": [
    "bird_classifiers['feather'] = finetune_into_binary(vgg_model.vgg19_bn(pretrained=True))\n",
    "feather_mapping = {0:0, 1:0, 2:1, 3:0, 4:0}\n",
    "finetune_model(bird_classifiers['feather'], train_params, feather_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.00 : Acc 0.129, F-1 0.229\n",
      "Threshold 0.10 : Acc 0.182, F-1 0.227\n",
      "Threshold 0.20 : Acc 0.717, F-1 0.163\n",
      "Threshold 0.30 : Acc 0.871, F-1 0.000\n",
      "Threshold 0.40 : Acc 0.871, F-1 0.000\n",
      "Threshold 0.50 : Acc 0.871, F-1 0.000\n",
      "Threshold 0.60 : Acc 0.871, F-1 0.000\n",
      "Threshold 0.70 : Acc 0.871, F-1 0.000\n",
      "Threshold 0.80 : Acc 0.871, F-1 0.000\n",
      "Threshold 0.90 : Acc 0.871, F-1 0.000\n",
      "Threshold 1.00 : Acc 0.871, F-1 0.000\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    acc = test_model(bird_classifiers['feather'], train_params, feather_mapping, i / 10)\n",
    "    print(\"Threshold %.2f : Acc %.3f, F-1 %.3f\" % (i/10, acc[0], acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "train loss: 0.648 , accuracy: 24.633, F-1: 0.319\n",
      "validation loss: 0.561 , accuracy: 21.940, F-1: 0.265\n",
      "Epoch : 2\n",
      "train loss: 0.552 , accuracy: 35.755, F-1: 0.321\n",
      "validation loss: 0.523 , accuracy: 28.848, F-1: 0.267\n",
      "Epoch : 3\n",
      "train loss: 0.528 , accuracy: 54.104, F-1: 0.315\n",
      "validation loss: 0.489 , accuracy: 74.465, F-1: 0.199\n",
      "Epoch : 4\n",
      "train loss: 0.511 , accuracy: 79.126, F-1: 0.244\n",
      "validation loss: 0.478 , accuracy: 89.581, F-1: 0.106\n",
      "Epoch : 5\n",
      "train loss: 0.511 , accuracy: 85.882, F-1: 0.183\n",
      "validation loss: 0.470 , accuracy: 93.323, F-1: 0.079\n",
      "Epoch : 6\n",
      "train loss: 0.504 , accuracy: 94.627, F-1: 0.121\n",
      "validation loss: 0.465 , accuracy: 95.567, F-1: 0.029\n",
      "Epoch : 7\n",
      "train loss: 0.502 , accuracy: 96.677, F-1: 0.070\n",
      "validation loss: 0.463 , accuracy: 96.263, F-1: 0.029\n",
      "Epoch : 8\n",
      "train loss: 0.503 , accuracy: 97.300, F-1: 0.099\n",
      "validation loss: 0.460 , accuracy: 96.645, F-1: 0.015\n",
      "Epoch : 9\n",
      "train loss: 0.496 , accuracy: 98.767, F-1: 0.056\n",
      "validation loss: 0.457 , accuracy: 97.189, F-1: nan\n",
      "Epoch : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.491 , accuracy: 101.465, F-1: 0.010\n",
      "validation loss: 0.454 , accuracy: 97.189, F-1: nan\n"
     ]
    }
   ],
   "source": [
    "bird_classifiers['feet'] = finetune_into_binary(vgg_model.vgg19_bn(pretrained=True))\n",
    "feet_mapping = {0:0, 1:0, 2:0, 3:1, 4:0}\n",
    "finetune_model(bird_classifiers['feet'], train_params, feet_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.00 : Acc 0.171, F-1 0.291\n",
      "Threshold 0.10 : Acc 0.191, F-1 0.294\n",
      "Threshold 0.20 : Acc 0.581, F-1 0.278\n",
      "Threshold 0.30 : Acc 0.829, F-1 0.000\n",
      "Threshold 0.40 : Acc 0.829, F-1 0.000\n",
      "Threshold 0.50 : Acc 0.829, F-1 0.000\n",
      "Threshold 0.60 : Acc 0.829, F-1 0.000\n",
      "Threshold 0.70 : Acc 0.829, F-1 0.000\n",
      "Threshold 0.80 : Acc 0.829, F-1 0.000\n",
      "Threshold 0.90 : Acc 0.829, F-1 0.000\n",
      "Threshold 1.00 : Acc 0.829, F-1 0.000\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    acc = test_model(bird_classifiers['feet'], train_params, feet_mapping, i / 10)\n",
    "    print(\"Threshold %.2f : Acc %.3f, F-1 %.3f\" % (i/10, acc[0], acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "train loss: 0.694 , accuracy: 32.551, F-1: 0.403\n",
      "validation loss: 0.653 , accuracy: 33.189, F-1: 0.365\n",
      "Epoch : 2\n",
      "train loss: 0.626 , accuracy: 34.577, F-1: 0.401\n",
      "validation loss: 0.641 , accuracy: 34.691, F-1: 0.362\n",
      "Epoch : 3\n",
      "train loss: 0.608 , accuracy: 41.639, F-1: 0.380\n",
      "validation loss: 0.636 , accuracy: 47.235, F-1: 0.325\n",
      "Epoch : 4\n",
      "train loss: 0.587 , accuracy: 55.869, F-1: 0.338\n",
      "validation loss: 0.633 , accuracy: 57.742, F-1: 0.290\n",
      "Epoch : 5\n",
      "train loss: 0.586 , accuracy: 60.776, F-1: 0.314\n",
      "validation loss: 0.634 , accuracy: 74.618, F-1: 0.205\n",
      "Epoch : 6\n",
      "train loss: 0.582 , accuracy: 73.295, F-1: 0.284\n",
      "validation loss: 0.633 , accuracy: 75.765, F-1: 0.218\n",
      "Epoch : 7\n",
      "train loss: 0.566 , accuracy: 74.092, F-1: 0.305\n",
      "validation loss: 0.622 , accuracy: 67.171, F-1: 0.278\n",
      "Epoch : 8\n",
      "train loss: 0.570 , accuracy: 65.551, F-1: 0.369\n",
      "validation loss: 0.624 , accuracy: 78.318, F-1: 0.236\n",
      "Epoch : 9\n",
      "train loss: 0.563 , accuracy: 72.214, F-1: 0.335\n",
      "validation loss: 0.632 , accuracy: 81.839, F-1: 0.178\n",
      "Epoch : 10\n",
      "train loss: 0.560 , accuracy: 77.559, F-1: 0.326\n",
      "validation loss: 0.626 , accuracy: 82.171, F-1: 0.207\n"
     ]
    }
   ],
   "source": [
    "bird_classifiers['wings'] = finetune_into_binary(vgg_model.vgg19_bn(pretrained=True))\n",
    "wings_mapping = {0:0, 1:0, 2:0, 3:0, 4:1}\n",
    "finetune_model(bird_classifiers['wings'], train_params, wings_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.00 : Acc 0.329, F-1 0.496\n",
      "Threshold 0.10 : Acc 0.329, F-1 0.496\n",
      "Threshold 0.20 : Acc 0.376, F-1 0.490\n",
      "Threshold 0.30 : Acc 0.682, F-1 0.425\n",
      "Threshold 0.40 : Acc 0.671, F-1 0.000\n",
      "Threshold 0.50 : Acc 0.671, F-1 0.000\n",
      "Threshold 0.60 : Acc 0.671, F-1 0.000\n",
      "Threshold 0.70 : Acc 0.671, F-1 0.000\n",
      "Threshold 0.80 : Acc 0.671, F-1 0.000\n",
      "Threshold 0.90 : Acc 0.671, F-1 0.000\n",
      "Threshold 1.00 : Acc 0.671, F-1 0.000\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    acc = test_model(bird_classifiers['wings'], train_params, wings_mapping, i / 10)\n",
    "    print(\"Threshold %.2f : Acc %.3f, F-1 %.3f\" % (i/10, acc[0], acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in bird_classifiers.items():\n",
    "    ch.save(v, \"./concept_classifiers/bird/\" + k + '.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car Concept Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = {'path': '/p/adversarialml/as9rw/dlvr_project/car_vs_bird/car/', 'batch_size': 128}\n",
    "train_loader, validation_loader = make_folder_loaders(data_params)\n",
    "train_params = {'description': 'Car-Concepts',\n",
    "                'num_epochs': 10,\n",
    "                'check_point': 5, 'device': device,\n",
    "                'train_loader': train_loader, 'validation_loader': validation_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bumper', 'door', 'headlight', 'side-view-mirror', 'tail-light', 'tire', 'window']\n",
      "{'bumper': 0, 'door': 1, 'headlight': 2, 'side-view-mirror': 3, 'tail-light': 4, 'tire': 5, 'window': 6}\n",
      "['bumper', 'door', 'headlight', 'side-view-mirror', 'tail-light', 'tire', 'window']\n",
      "{'bumper': 0, 'door': 1, 'headlight': 2, 'side-view-mirror': 3, 'tail-light': 4, 'tire': 5, 'window': 6}\n"
     ]
    }
   ],
   "source": [
    "print(train_loader.dataset.classes)\n",
    "print(train_loader.dataset.class_to_idx)\n",
    "print(validation_loader.dataset.classes)\n",
    "print(validation_loader.dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tail-light': None, 'side-view-mirror': None, 'bumper': None, 'tire': None, 'headlight': None, 'window': None, 'door': None}\n"
     ]
    }
   ],
   "source": [
    "basepath = \"./car_vs_bird/car/train\"\n",
    "car_classifiers = {x:None for x in os.listdir(basepath)}\n",
    "print(car_classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.556 , accuracy: 24.166, F-1: 0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.459 , accuracy: 56.051, F-1: 0.106\n",
      "Epoch : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.410 , accuracy: 85.839, F-1: 0.162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.383 , accuracy: 105.801, F-1: 0.038\n",
      "Epoch : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.363 , accuracy: 108.241, F-1: 0.091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.357 , accuracy: 113.316, F-1: nan\n",
      "Epoch : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.352 , accuracy: 111.796, F-1: 0.022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.346 , accuracy: 113.316, F-1: nan\n",
      "Epoch : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.336 , accuracy: 112.203, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.341 , accuracy: 113.316, F-1: nan\n",
      "Epoch : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.334 , accuracy: 112.562, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.338 , accuracy: 113.316, F-1: nan\n",
      "Epoch : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.333 , accuracy: 112.158, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.337 , accuracy: 113.316, F-1: nan\n",
      "Epoch : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.333 , accuracy: 112.337, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.336 , accuracy: 113.316, F-1: nan\n",
      "Epoch : 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.332 , accuracy: 112.293, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.335 , accuracy: 113.316, F-1: nan\n",
      "Epoch : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.330 , accuracy: 112.248, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.335 , accuracy: 113.316, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "car_classifiers['bumper'] = finetune_into_binary(vgg_model.vgg19_bn(pretrained=True))\n",
    "bumper_mapping = {0:1, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0}\n",
    "finetune_model(car_classifiers['bumper'], train_params, bumper_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.522 , accuracy: 31.061, F-1: 0.206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.435 , accuracy: 65.741, F-1: 0.185\n",
      "Epoch : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.396 , accuracy: 91.732, F-1: 0.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.367 , accuracy: 111.547, F-1: 0.077\n",
      "Epoch : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.360 , accuracy: 109.033, F-1: 0.088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.342 , accuracy: 112.506, F-1: nan\n",
      "Epoch : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.340 , accuracy: 110.924, F-1: 0.056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.332 , accuracy: 112.506, F-1: nan\n",
      "Epoch : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.335 , accuracy: 111.294, F-1: 0.042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.328 , accuracy: 112.506, F-1: nan\n",
      "Epoch : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.339 , accuracy: 111.488, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.326 , accuracy: 112.506, F-1: nan\n",
      "Epoch : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.329 , accuracy: 111.448, F-1: 0.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.324 , accuracy: 112.506, F-1: nan\n",
      "Epoch : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.329 , accuracy: 111.495, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.323 , accuracy: 112.506, F-1: nan\n",
      "Epoch : 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.329 , accuracy: 111.329, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.323 , accuracy: 112.506, F-1: nan\n",
      "Epoch : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.324 , accuracy: 111.380, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.322 , accuracy: 112.506, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "car_classifiers['door'] = finetune_into_binary(vgg_model.vgg19_bn(pretrained=True))\n",
    "door_mapping = {0:0, 1:1, 2:0, 3:0, 4:0, 5:0, 6:0}\n",
    "finetune_model(car_classifiers['door'], train_params, door_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.639 , accuracy: 25.314, F-1: 0.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.559 , accuracy: 25.725, F-1: 0.194\n",
      "Epoch : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.532 , accuracy: 50.399, F-1: 0.302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.514 , accuracy: 73.399, F-1: 0.098\n",
      "Epoch : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.507 , accuracy: 82.841, F-1: 0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.502 , accuracy: 99.759, F-1: 0.019\n",
      "Epoch : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.500 , accuracy: 93.713, F-1: 0.161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.498 , accuracy: 101.975, F-1: nan\n",
      "Epoch : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.499 , accuracy: 97.701, F-1: 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.497 , accuracy: 102.380, F-1: nan\n",
      "Epoch : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.500 , accuracy: 98.068, F-1: 0.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.496 , accuracy: 102.380, F-1: nan\n",
      "Epoch : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.498 , accuracy: 99.159, F-1: 0.075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.496 , accuracy: 102.380, F-1: nan\n",
      "Epoch : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.494 , accuracy: 99.397, F-1: 0.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.495 , accuracy: 102.380, F-1: nan\n",
      "Epoch : 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.495 , accuracy: 99.747, F-1: 0.069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.494 , accuracy: 102.380, F-1: nan\n",
      "Epoch : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.490 , accuracy: 99.990, F-1: 0.055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.494 , accuracy: 102.380, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "car_classifiers['headlight'] = finetune_into_binary(vgg_model.vgg19_bn(pretrained=True))\n",
    "headlight_mapping = {0:0, 1:0, 2:1, 3:0, 4:0, 5:0, 6:0}\n",
    "finetune_model(car_classifiers['headlight'], train_params, headlight_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.542 , accuracy: 24.701, F-1: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.458 , accuracy: 50.551, F-1: 0.110\n",
      "Epoch : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.412 , accuracy: 88.762, F-1: 0.137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.393 , accuracy: 112.709, F-1: nan\n",
      "Epoch : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.374 , accuracy: 110.961, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.371 , accuracy: 112.709, F-1: nan\n",
      "Epoch : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.357 , accuracy: 111.916, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.363 , accuracy: 112.709, F-1: nan\n",
      "Epoch : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.346 , accuracy: 112.076, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.358 , accuracy: 112.709, F-1: nan\n",
      "Epoch : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.346 , accuracy: 112.121, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.355 , accuracy: 112.709, F-1: nan\n",
      "Epoch : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.343 , accuracy: 112.076, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.353 , accuracy: 112.709, F-1: nan\n",
      "Epoch : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.337 , accuracy: 112.121, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.352 , accuracy: 112.709, F-1: nan\n",
      "Epoch : 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.335 , accuracy: 112.121, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.350 , accuracy: 112.709, F-1: nan\n",
      "Epoch : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.333 , accuracy: 112.256, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.349 , accuracy: 112.709, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "car_classifiers['side-view-mirror'] = finetune_into_binary(vgg_model.vgg19_bn(pretrained=True))\n",
    "svm_mapping = {0:0, 1:0, 2:0, 3:1, 4:0, 5:0, 6:0}\n",
    "finetune_model(car_classifiers['side-view-mirror'], train_params, svm_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.558 , accuracy: 22.050, F-1: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.452 , accuracy: 46.978, F-1: 0.142\n",
      "Epoch : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.398 , accuracy: 85.189, F-1: 0.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.367 , accuracy: 107.889, F-1: 0.018\n",
      "Epoch : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.351 , accuracy: 110.102, F-1: 0.055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.343 , accuracy: 113.722, F-1: nan\n",
      "Epoch : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.337 , accuracy: 112.276, F-1: 0.046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.332 , accuracy: 113.722, F-1: nan\n",
      "Epoch : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.330 , accuracy: 112.895, F-1: 0.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.327 , accuracy: 113.722, F-1: nan\n",
      "Epoch : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.323 , accuracy: 112.947, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.323 , accuracy: 113.722, F-1: nan\n",
      "Epoch : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.319 , accuracy: 112.767, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.322 , accuracy: 113.722, F-1: nan\n",
      "Epoch : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.321 , accuracy: 113.011, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.321 , accuracy: 113.722, F-1: nan\n",
      "Epoch : 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.320 , accuracy: 112.992, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.320 , accuracy: 113.722, F-1: nan\n",
      "Epoch : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.319 , accuracy: 112.902, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.320 , accuracy: 113.722, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "car_classifiers['tail-light'] = finetune_into_binary(vgg_model.vgg19_bn(pretrained=True))\n",
    "taillight_mapping = {0:0, 1:0, 2:0, 3:0, 4:1, 5:0, 6:0}\n",
    "finetune_model(car_classifiers['tail-light'], train_params, taillight_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.641 , accuracy: 29.782, F-1: 0.337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.578 , accuracy: 28.184, F-1: 0.263\n",
      "Epoch : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.559 , accuracy: 46.233, F-1: 0.320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.537 , accuracy: 67.291, F-1: 0.191\n",
      "Epoch : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.529 , accuracy: 70.347, F-1: 0.315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.520 , accuracy: 92.259, F-1: 0.162\n",
      "Epoch : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.516 , accuracy: 82.895, F-1: 0.338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.509 , accuracy: 95.544, F-1: 0.153\n",
      "Epoch : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.507 , accuracy: 84.799, F-1: 0.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.500 , accuracy: 95.886, F-1: 0.113\n",
      "Epoch : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.498 , accuracy: 85.781, F-1: 0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.492 , accuracy: 97.165, F-1: 0.152\n",
      "Epoch : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.492 , accuracy: 87.961, F-1: 0.344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.485 , accuracy: 98.241, F-1: 0.168\n",
      "Epoch : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.487 , accuracy: 85.231, F-1: 0.406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.480 , accuracy: 99.285, F-1: 0.176\n",
      "Epoch : 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.477 , accuracy: 83.593, F-1: 0.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.474 , accuracy: 98.101, F-1: 0.230\n",
      "Epoch : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.470 , accuracy: 83.165, F-1: 0.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.470 , accuracy: 97.525, F-1: 0.230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "car_classifiers['tire'] = finetune_into_binary(vgg_model.vgg19_bn(pretrained=True))\n",
    "tire_mapping = {0:0, 1:0, 2:0, 3:0, 4:0, 5:1, 6:0}\n",
    "finetune_model(car_classifiers['tire'], train_params, tire_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.584 , accuracy: 28.830, F-1: 0.303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.529 , accuracy: 34.753, F-1: 0.181\n",
      "Epoch : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.504 , accuracy: 60.912, F-1: 0.313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.485 , accuracy: 88.310, F-1: 0.064\n",
      "Epoch : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.485 , accuracy: 89.234, F-1: 0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.472 , accuracy: 104.709, F-1: 0.013\n",
      "Epoch : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.478 , accuracy: 98.161, F-1: 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.467 , accuracy: 104.835, F-1: nan\n",
      "Epoch : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.476 , accuracy: 100.249, F-1: 0.092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.464 , accuracy: 104.835, F-1: nan\n",
      "Epoch : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.471 , accuracy: 100.803, F-1: 0.040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.463 , accuracy: 104.835, F-1: nan\n",
      "Epoch : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.474 , accuracy: 101.452, F-1: 0.049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.462 , accuracy: 104.835, F-1: nan\n",
      "Epoch : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.468 , accuracy: 101.727, F-1: 0.054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.460 , accuracy: 104.835, F-1: nan\n",
      "Epoch : 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.474 , accuracy: 101.483, F-1: 0.018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.459 , accuracy: 104.835, F-1: nan\n",
      "Epoch : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.466 , accuracy: 100.590, F-1: 0.080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.458 , accuracy: 104.835, F-1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/u/as9rw/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "car_classifiers['window'] = finetune_into_binary(vgg_model.vgg19_bn(pretrained=True))\n",
    "window_mapping = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:1}\n",
    "finetune_model(car_classifiers['window'], train_params, window_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in car_classifiers.items():\n",
    "    ch.save(v, \"./concept_classifiers/car/\" + k + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Construct artificial CIFAR10 car/bird data\n",
    "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.ColorJitter(.25,.25,.25),\n",
    "                                          transforms.RandomRotation(2),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "    \n",
    "transform_validation = transforms.Compose([transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = ch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_validation)\n",
    "testloader = ch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_val, Y_val = [], [], [], []\n",
    "for x,y in trainloader:\n",
    "    X_train.append(x)\n",
    "    Y_train.append(y)\n",
    "X_train = ch.cat(X_train, 0)\n",
    "Y_train = ch.cat(Y_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 3, 32, 32]) torch.Size([5000, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Filter out relevant data\n",
    "car_indices = (Y_train == 1)\n",
    "bird_indices = (Y_train == 2)\n",
    "\n",
    "print(X_train[car_indices].shape, X_train[bird_indices].shape)\n",
    "X_train_ = ch.cat([X_train[car_indices], X_train[bird_indices]], 0)\n",
    "Y_train_ = ch.cat([Y_train[car_indices], Y_train[bird_indices]], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in testloader:\n",
    "    X_val.append(x)\n",
    "    Y_val.append(y)\n",
    "X_val = ch.cat(X_val, 0)\n",
    "Y_val = ch.cat(Y_val, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3, 32, 32]) torch.Size([1000, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Filter out relevant data\n",
    "car_indices = (Y_val == 1)\n",
    "bird_indices = (Y_val == 2)\n",
    "\n",
    "print(X_val[car_indices].shape, X_val[bird_indices].shape)\n",
    "X_val_ = ch.cat([X_val[car_indices], X_val[bird_indices]], 0)\n",
    "Y_val_ = ch.cat([Y_val[car_indices], Y_val[bird_indices]], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_ = (Y_val_ == 2) * 1\n",
    "Y_train_ = (Y_train_ == 2) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [03:13<00:00, 51.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "X_actual_train = []\n",
    "for x in tqdm(X_train_):\n",
    "    features = []\n",
    "    for k, v in car_classifiers.items():\n",
    "        if v is None:\n",
    "            continue\n",
    "        score = v(x.unsqueeze(0).cuda())\n",
    "        features.append(score.item())\n",
    "    X_actual_train.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:38<00:00, 51.67it/s]\n"
     ]
    }
   ],
   "source": [
    "X_actual_val = []\n",
    "for x in tqdm(X_val_):\n",
    "    features = []\n",
    "    for k, v in car_classifiers.items():\n",
    "        if v is None:\n",
    "            continue\n",
    "        score = v(x.unsqueeze(0).cuda())\n",
    "        features.append(score.item())\n",
    "    X_actual_val.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=5, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=5, random_state=0)\n",
    "clf.fit(X_actual_train, Y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9765"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_actual_val, Y_val_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9765"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_actual_val, Y_val_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
